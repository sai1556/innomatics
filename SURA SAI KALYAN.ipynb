{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb707cc0-20a9-4559-91eb-703bb80bbe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\suras\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\suras\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\suras\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\suras\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\suras\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\suras\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f781c36-667d-4a94-bfa2-2477c39d40f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\suras\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3131f496-70b4-4ccd-83d8-8c8292602051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: C:/Users/suras/Downloads/extracted_files\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "zip_file_path = \"C:/Users/suras/Downloads/drive-download-20250109T055326Z-001.zip\"\n",
    "extracted_folder = \"C:/Users/suras/Downloads/extracted_files\"\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder)\n",
    "print(f\"Files extracted to: {extracted_folder}\")\n",
    "csv_files = [os.path.join(extracted_folder, file) for file in os.listdir(extracted_folder) if file.endswith('.csv')]\n",
    "dataframes = []\n",
    "def read_csv_with_encoding(file_path):\n",
    "    encoding = 'utf-8' \n",
    "    try:\n",
    "        return pd.read_csv(file_path, encoding=encoding)\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(file_path, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "292dd08c-2389-4dcc-8476-f63954b1a49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet in c:\\users\\suras\\anaconda3\\lib\\site-packages (4.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chardet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d3951f9c-5ad8-401b-9812-0508b16031e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 CSV files:\n",
      "Akshayanagar.csv\n",
      "Arekere.csv\n",
      "Banashankari.csv\n",
      "Basavanagudi.csv\n",
      "Basaveshwar Nagar.csv\n",
      "Begur.csv\n",
      "Bellandur.csv\n",
      "Bilekahalli.csv\n",
      "Bommanahalli.csv\n",
      "Brookefield.csv\n",
      "BTM 2nd Stage.csv\n",
      "BTM_Layout.csv\n",
      "Chikkalasandra.csv\n",
      "Doddanekundi.csv\n",
      "Ejipura.csv\n",
      "Electronic City.csv\n",
      "Electronics City Phase 1.csv\n",
      "Gottigere.csv\n",
      "HBR Layout.csv\n",
      "Hebbal.csv\n",
      "Hongasandra.csv\n",
      "Hoodi.csv\n",
      "Horamavu.csv\n",
      "Hosakerehalli.csv\n",
      "HSR_Layout.csv\n",
      "Hulimavu.csv\n",
      "Indiranagar.csv\n",
      "Jayanagar.csv\n",
      "JP Nagar.csv\n",
      "K.R Puram.csv\n",
      "Kadugodi.csv\n",
      "Kaggadasapura.csv\n",
      "Kalyan Nagar.csv\n",
      "Kammanahalli.csv\n",
      "Kasavanahalli.csv\n",
      "Kengeri Satellite Town.csv\n",
      "Kengeri.csv\n",
      "Konanakunte.csv\n",
      "Koramangala.csv\n",
      "Krishnarajapura.csv\n",
      "Kumaraswamy Layout.csv\n",
      "Lingarajapuram.csv\n",
      "Mahadevapura.csv\n",
      "Marathahalli.csv\n",
      "Mathikere.csv\n",
      "Munnekollal.csv\n",
      "Nagarbhavi.csv\n",
      "Padmanabhanagar.csv\n",
      "Raja Rajeshwari Nagar.csv\n",
      "Rajaji Nagar.csv\n",
      "Ramamurthy Nagar.csv\n",
      "RR Nagar.csv\n",
      "RT Nagar.csv\n",
      "Singasandra.csv\n",
      "Subramanyapura.csv\n",
      "Sunkadakatte.csv\n",
      "Thanisandra.csv\n",
      "Uttarahalli Hobli.csv\n",
      "Varthur.csv\n",
      "Vidyaranyapura.csv\n",
      "Vijaya Nagar.csv\n",
      "Whitefield.csv\n",
      "Yelahanka New Town.csv\n",
      "Yelahanka.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "extracted_folder = \"C:/Users/suras/Downloads/extracted_files\"\n",
    "all_files = os.listdir(extracted_folder)\n",
    "csv_files = [file for file in all_files if file.endswith('.csv')]\n",
    "print(f\"Found {len(csv_files)} CSV files:\")\n",
    "for file in csv_files:\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "66e07ea2-b5b8-43bf-a8bc-0c3dc737bdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read Akshayanagar.csv with encoding ascii\n",
      "Successfully read Arekere.csv with encoding ascii\n",
      "Successfully read Banashankari.csv with encoding ascii\n",
      "Successfully read Basavanagudi.csv with encoding ascii\n",
      "Successfully read Basaveshwar Nagar.csv with encoding ascii\n",
      "Successfully read Begur.csv with encoding ascii\n",
      "Successfully read Bellandur.csv with encoding ascii\n",
      "Successfully read Bilekahalli.csv with encoding ascii\n",
      "Successfully read Bommanahalli.csv with encoding ascii\n",
      "Successfully read Brookefield.csv with encoding ascii\n",
      "Successfully read BTM 2nd Stage.csv with encoding ascii\n",
      "Successfully read BTM_Layout.csv with encoding ascii\n",
      "Successfully read Chikkalasandra.csv with encoding ascii\n",
      "Successfully read Doddanekundi.csv with encoding ascii\n",
      "Successfully read Ejipura.csv with encoding ascii\n",
      "Successfully read Electronic City.csv with encoding ascii\n",
      "Successfully read Electronics City Phase 1.csv with encoding ascii\n",
      "Successfully read Gottigere.csv with encoding ascii\n",
      "Successfully read HBR Layout.csv with encoding ascii\n",
      "Successfully read Hebbal.csv with encoding ascii\n",
      "Successfully read Hongasandra.csv with encoding ascii\n",
      "Successfully read Hoodi.csv with encoding ascii\n",
      "Successfully read Horamavu.csv with encoding ascii\n",
      "Successfully read Hosakerehalli.csv with encoding ascii\n",
      "Successfully read HSR_Layout.csv with encoding UTF-32\n",
      "Successfully read Hulimavu.csv with encoding ascii\n",
      "Successfully read Indiranagar.csv with encoding ascii\n",
      "Successfully read Jayanagar.csv with encoding ascii\n",
      "Successfully read JP Nagar.csv with encoding ascii\n",
      "Successfully read K.R Puram.csv with encoding ascii\n",
      "Successfully read Kadugodi.csv with encoding ascii\n",
      "Successfully read Kaggadasapura.csv with encoding ascii\n",
      "Successfully read Kalyan Nagar.csv with encoding ascii\n",
      "Successfully read Kammanahalli.csv with encoding ascii\n",
      "Successfully read Kasavanahalli.csv with encoding ascii\n",
      "Successfully read Kengeri Satellite Town.csv with encoding ascii\n",
      "Successfully read Kengeri.csv with encoding ascii\n",
      "Successfully read Konanakunte.csv with encoding ascii\n",
      "Successfully read Koramangala.csv with encoding ascii\n",
      "Successfully read Krishnarajapura.csv with encoding ascii\n",
      "Successfully read Kumaraswamy Layout.csv with encoding ascii\n",
      "Successfully read Lingarajapuram.csv with encoding ascii\n",
      "Successfully read Mahadevapura.csv with encoding ascii\n",
      "Successfully read Marathahalli.csv with encoding ascii\n",
      "Successfully read Mathikere.csv with encoding ascii\n",
      "Successfully read Munnekollal.csv with encoding ascii\n",
      "Successfully read Nagarbhavi.csv with encoding ascii\n",
      "Successfully read Padmanabhanagar.csv with encoding ascii\n",
      "Successfully read Raja Rajeshwari Nagar.csv with encoding ascii\n",
      "Successfully read Rajaji Nagar.csv with encoding ascii\n",
      "Successfully read Ramamurthy Nagar.csv with encoding ascii\n",
      "Successfully read RR Nagar.csv with encoding ascii\n",
      "Successfully read RT Nagar.csv with encoding ascii\n",
      "Successfully read Singasandra.csv with encoding ascii\n",
      "Successfully read Subramanyapura.csv with encoding ascii\n",
      "Successfully read Sunkadakatte.csv with encoding ascii\n",
      "Successfully read Thanisandra.csv with encoding ascii\n",
      "Successfully read Uttarahalli Hobli.csv with encoding ascii\n",
      "Successfully read Varthur.csv with encoding ascii\n",
      "Successfully read Vidyaranyapura.csv with encoding ascii\n",
      "Successfully read Vijaya Nagar.csv with encoding ascii\n",
      "Successfully read Whitefield.csv with encoding ascii\n",
      "Successfully read Yelahanka New Town.csv with encoding ascii\n",
      "Successfully read Yelahanka.csv with encoding ascii\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/suras/Downloads/merged_output.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 60\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Optionally, you can drop duplicates if necessary\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# merged_df.drop_duplicates(inplace=True)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Save the merged DataFrame to a single CSV file\u001b[39;00m\n\u001b[0;32m     59\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/suras/Downloads/merged_output.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 60\u001b[0m merged_df\u001b[38;5;241m.\u001b[39mto_csv(output_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerged CSV file saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3968\u001b[0m     path_or_buf,\n\u001b[0;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3984\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/Users/suras/Downloads/merged_output.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import chardet\n",
    "extracted_folder = \"C:/Users/suras/Downloads/extracted_files\"\n",
    "csv_files = [file for file in os.listdir(extracted_folder) if file.endswith('.csv')]\n",
    "dataframes = []\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read(100000))  \n",
    "        return result['encoding']\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(extracted_folder, file)\n",
    "    try:\n",
    "        encoding = detect_encoding(file_path)\n",
    "        df = pd.read_csv(file_path, encoding=encoding)\n",
    "        dataframes.append(df)\n",
    "        print(f\"Successfully read {file} with encoding {encoding}\")\n",
    "        \n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"UnicodeDecodeError for {file} with encoding {encoding}: {e}\")\n",
    "        print(\"Attempting to read with 'latin1' encoding...\")\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='latin1')\n",
    "            dataframes.append(df)\n",
    "            print(f\"Successfully read {file} with 'latin1' encoding\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Failed to read {file} even with 'latin1' encoding: {e2}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"EmptyDataError: {file} is empty and will be skipped.\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"ParserError for {file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while reading {file}: {e}\")\n",
    "if not dataframes:\n",
    "    print(\"No DataFrames were loaded. Please check your CSV files.\")\n",
    "else:\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    output_path = \"C:/Users/suras/Downloads/merged_output.csv\"\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f\"Merged CSV file saved as '{output_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8b26b34-55c0-47b9-b826-2c0a2f1a868c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape of the merged DataFrame: (14100, 23)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final shape of the merged DataFrame: {merged_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f03b982-fab1-41d6-852c-00e3aee62cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           bathroom         floor   total_floor      latitude     longitude  \\\n",
      "count  13435.000000  13435.000000  13416.000000  13435.000000  13435.000000   \n",
      "mean       1.831634      1.852921      3.642665     12.949500     77.604504   \n",
      "std        0.774056      2.489091      3.385582      0.208342      1.162160   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        1.000000      0.000000      2.000000     12.906064     77.564663   \n",
      "50%        2.000000      1.000000      3.000000     12.943637     77.614939   \n",
      "75%        2.000000      2.000000      4.000000     12.997176     77.677067   \n",
      "max       21.000000    123.000000     38.000000     17.418143     80.256293   \n",
      "\n",
      "       property_age  property_size      pin_code          rent       deposit  \n",
      "count  13435.000000   13435.000000  1.331300e+04  13435.000000  1.343500e+04  \n",
      "mean       4.344325     992.357722  5.610532e+05  14610.660737  1.225911e+05  \n",
      "std        6.364126     676.653400  7.623651e+04   8631.177518  1.208666e+05  \n",
      "min        0.000000       0.000000  0.000000e+00   1000.000000  0.000000e+00  \n",
      "25%        0.000000     600.000000  5.600430e+05   8500.000000  5.000000e+04  \n",
      "50%        3.000000     950.000000  5.600670e+05  13000.000000  1.000000e+05  \n",
      "75%        6.000000    1233.500000  5.600780e+05  18000.000000  1.500000e+05  \n",
      "max      457.000000   40000.000000  5.600035e+06  75000.000000  3.000000e+06  \n",
      "property_id                                                                                                                                                                                                      665\n",
      "type                                                                                                                                                                                                             665\n",
      "activation_date                                                                                                                                                                                                  665\n",
      "bathroom                                                                                                                                                                                                         665\n",
      "floor                                                                                                                                                                                                            665\n",
      "total_floor                                                                                                                                                                                                      684\n",
      "furnishing                                                                                                                                                                                                       665\n",
      "gym                                                                                                                                                                                                              665\n",
      "latitude                                                                                                                                                                                                         665\n",
      "longitude                                                                                                                                                                                                        665\n",
      "lease_type                                                                                                                                                                                                       665\n",
      "lift                                                                                                                                                                                                             665\n",
      "locality                                                                                                                                                                                                         889\n",
      "parking                                                                                                                                                                                                          665\n",
      "property_age                                                                                                                                                                                                     665\n",
      "property_size                                                                                                                                                                                                    665\n",
      "swimming_pool                                                                                                                                                                                                    665\n",
      "pin_code                                                                                                                                                                                                         787\n",
      "rent                                                                                                                                                                                                             665\n",
      "deposit                                                                                                                                                                                                          665\n",
      "building_type                                                                                                                                                                                                    703\n",
      "location                                                                                                                                                                                                       13876\n",
      "property_id/type/activation_date/bathroom/floor/total_floor/furnishing/gym/latitude/longitude/lease_type/lift/locality/parking/property_age/property_size/swimming_pool/pin_code/rent/deposit/building_type    13435\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'column_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'column_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Example: Distribution of a column\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m sns\u001b[38;5;241m.\u001b[39mhistplot(merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_name\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'column_name'"
     ]
    }
   ],
   "source": [
    "print(merged_df.describe())\n",
    "print(merged_df.isnull().sum())\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.histplot(merged_df['column_name'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "131a188b-74b4-451f-af02-9d6ffab02c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read Akshayanagar.csv with encoding ascii\n",
      "Successfully read Arekere.csv with encoding ascii\n",
      "Successfully read Banashankari.csv with encoding ascii\n",
      "Successfully read Basavanagudi.csv with encoding ascii\n",
      "Successfully read Basaveshwar Nagar.csv with encoding ascii\n",
      "Successfully read Begur.csv with encoding ascii\n",
      "Successfully read Bellandur.csv with encoding ascii\n",
      "Successfully read Bilekahalli.csv with encoding ascii\n",
      "Successfully read Bommanahalli.csv with encoding ascii\n",
      "Successfully read Brookefield.csv with encoding ascii\n",
      "Successfully read BTM 2nd Stage.csv with encoding ascii\n",
      "Successfully read BTM_Layout.csv with encoding ascii\n",
      "Successfully read Chikkalasandra.csv with encoding ascii\n",
      "Successfully read Doddanekundi.csv with encoding ascii\n",
      "Successfully read Ejipura.csv with encoding ascii\n",
      "Successfully read Electronic City.csv with encoding ascii\n",
      "Successfully read Electronics City Phase 1.csv with encoding ascii\n",
      "Successfully read Gottigere.csv with encoding ascii\n",
      "Successfully read HBR Layout.csv with encoding ascii\n",
      "Successfully read Hebbal.csv with encoding ascii\n",
      "Successfully read Hongasandra.csv with encoding ascii\n",
      "Successfully read Hoodi.csv with encoding ascii\n",
      "Successfully read Horamavu.csv with encoding ascii\n",
      "Successfully read Hosakerehalli.csv with encoding ascii\n",
      "Successfully read HSR_Layout.csv with encoding UTF-32\n",
      "Successfully read Hulimavu.csv with encoding ascii\n",
      "Successfully read Indiranagar.csv with encoding ascii\n",
      "Successfully read Jayanagar.csv with encoding ascii\n",
      "Successfully read JP Nagar.csv with encoding ascii\n",
      "Successfully read K.R Puram.csv with encoding ascii\n",
      "Successfully read Kadugodi.csv with encoding ascii\n",
      "Successfully read Kaggadasapura.csv with encoding ascii\n",
      "Successfully read Kalyan Nagar.csv with encoding ascii\n",
      "Successfully read Kammanahalli.csv with encoding ascii\n",
      "Successfully read Kasavanahalli.csv with encoding ascii\n",
      "Successfully read Kengeri Satellite Town.csv with encoding ascii\n",
      "Successfully read Kengeri.csv with encoding ascii\n",
      "Successfully read Konanakunte.csv with encoding ascii\n",
      "Successfully read Koramangala.csv with encoding ascii\n",
      "Successfully read Krishnarajapura.csv with encoding ascii\n",
      "Successfully read Kumaraswamy Layout.csv with encoding ascii\n",
      "Successfully read Lingarajapuram.csv with encoding ascii\n",
      "Successfully read Mahadevapura.csv with encoding ascii\n",
      "Successfully read Marathahalli.csv with encoding ascii\n",
      "Successfully read Mathikere.csv with encoding ascii\n",
      "Successfully read Munnekollal.csv with encoding ascii\n",
      "Successfully read Nagarbhavi.csv with encoding ascii\n",
      "Successfully read Padmanabhanagar.csv with encoding ascii\n",
      "Successfully read Raja Rajeshwari Nagar.csv with encoding ascii\n",
      "Successfully read Rajaji Nagar.csv with encoding ascii\n",
      "Successfully read Ramamurthy Nagar.csv with encoding ascii\n",
      "Successfully read RR Nagar.csv with encoding ascii\n",
      "Successfully read RT Nagar.csv with encoding ascii\n",
      "Successfully read Singasandra.csv with encoding ascii\n",
      "Successfully read Subramanyapura.csv with encoding ascii\n",
      "Successfully read Sunkadakatte.csv with encoding ascii\n",
      "Successfully read Thanisandra.csv with encoding ascii\n",
      "Successfully read Uttarahalli Hobli.csv with encoding ascii\n",
      "Successfully read Varthur.csv with encoding ascii\n",
      "Successfully read Vidyaranyapura.csv with encoding ascii\n",
      "Successfully read Vijaya Nagar.csv with encoding ascii\n",
      "Successfully read Whitefield.csv with encoding ascii\n",
      "Successfully read Yelahanka New Town.csv with encoding ascii\n",
      "Successfully read Yelahanka.csv with encoding ascii\n",
      "Final shape of the combined property data: (14100, 23)\n",
      "Merged CSV file saved as 'C:/Users/suras/Downloads/merged_output.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import chardet\n",
    "extracted_folder = \"C:/Users/suras/Downloads/extracted_files\"\n",
    "csv_files = [file for file in os.listdir(extracted_folder) if file.endswith('.csv')]\n",
    "dataframes = []\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read(100000))  \n",
    "        return result['encoding']\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(extracted_folder, file)\n",
    "    try:\n",
    "        encoding = detect_encoding(file_path)\n",
    "        df = pd.read_csv(file_path, encoding=encoding)\n",
    "        dataframes.append(df)\n",
    "        print(f\"Successfully read {file} with encoding {encoding}\")\n",
    "        \n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"UnicodeDecodeError for {file} with encoding {encoding}: {e}\")\n",
    "        print(\"Attempting to read with 'latin1' encoding...\")\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='latin1')\n",
    "            dataframes.append(df)\n",
    "            print(f\"Successfully read {file} with 'latin1' encoding\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Failed to read {file} even with 'latin1' encoding: {e2}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"EmptyDataError: {file} is empty and will be skipped.\")\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"ParserError for {file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while reading {file}: {e}\")\n",
    "if not dataframes:\n",
    "    print(\"No DataFrames were loaded. Please check your CSV files.\")\n",
    "else:\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    merged_df.dropna(axis=1, how='all', inplace=True)\n",
    "    merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]\n",
    "    print(\"Final shape of the combined property data:\", merged_df.shape)\n",
    "    output_path = \"C:/Users/suras/Downloads/merged_output.csv\"\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f\"Merged CSV file saved as '{output_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "92812ed6-7c70-491a-b436-5982b587753f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape of the combined property data: (14100, 23)\n"
     ]
    }
   ],
   "source": [
    "# Check the final shape of the merged DataFrame\n",
    "print(\"Final shape of the combined property data:\", merged_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b850887d-5ad2-40c5-98e7-01a39d4ff060",
   "metadata": {},
   "outputs": [],
   "source": [
    "erged_df=merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4cbadca0-9edc-43a2-b5fa-04720561d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmerged_df = erged_df.loc[:, ~erged_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0fa42527-1e57-43cd-8bc0-847b95363ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>type</th>\n",
       "      <th>activation_date</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>floor</th>\n",
       "      <th>total_floor</th>\n",
       "      <th>furnishing</th>\n",
       "      <th>gym</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>parking</th>\n",
       "      <th>property_age</th>\n",
       "      <th>property_size</th>\n",
       "      <th>swimming_pool</th>\n",
       "      <th>pin_code</th>\n",
       "      <th>rent</th>\n",
       "      <th>deposit</th>\n",
       "      <th>building_type</th>\n",
       "      <th>location</th>\n",
       "      <th>property_id/type/activation_date/bathroom/floor/total_floor/furnishing/gym/latitude/longitude/lease_type/lift/locality/parking/property_age/property_size/swimming_pool/pin_code/rent/deposit/building_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ff8080814a078fd2014a15c813ff0b03</td>\n",
       "      <td>BHK3</td>\n",
       "      <td>20-02-2017 09:24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>1</td>\n",
       "      <td>12.872456</td>\n",
       "      <td>77.617578</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>560068.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ff8081814c2dea94014c50865ea35904</td>\n",
       "      <td>BHK2</td>\n",
       "      <td>11-03-2017 16:12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>0</td>\n",
       "      <td>12.876009</td>\n",
       "      <td>77.617934</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>560076.0</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>IF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ff8081814cff7251014d04e2cc7018fd</td>\n",
       "      <td>BHK2</td>\n",
       "      <td>18-03-2017 14:26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>1</td>\n",
       "      <td>12.875923</td>\n",
       "      <td>77.617946</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>1</td>\n",
       "      <td>560068.0</td>\n",
       "      <td>17500.0</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ff8081814eb65997014ebbaa22f11869</td>\n",
       "      <td>BHK2</td>\n",
       "      <td>28-03-2017 11:09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>1</td>\n",
       "      <td>12.859438</td>\n",
       "      <td>77.614948</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>560076.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ff8081814fa8748d014fabcabea10bb6</td>\n",
       "      <td>BHK3</td>\n",
       "      <td>14-02-2017 17:07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>0</td>\n",
       "      <td>12.875697</td>\n",
       "      <td>77.617187</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>0</td>\n",
       "      <td>560076.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14095</th>\n",
       "      <td>ff8081815b15c304015b18b33e467d05</td>\n",
       "      <td>BHK3</td>\n",
       "      <td>29-03-2017 12:30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>1</td>\n",
       "      <td>13.114465</td>\n",
       "      <td>77.578528</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>0</td>\n",
       "      <td>560064.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14096</th>\n",
       "      <td>ff8081815b15c304015b18f78f4e2503</td>\n",
       "      <td>BHK2</td>\n",
       "      <td>29-03-2017 13:18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>1</td>\n",
       "      <td>13.122433</td>\n",
       "      <td>77.582765</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>1</td>\n",
       "      <td>560064.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14097</th>\n",
       "      <td>ff8081815b15c304015b1a4c67134ce4</td>\n",
       "      <td>BHK3</td>\n",
       "      <td>30-03-2017 14:10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>1</td>\n",
       "      <td>13.097357</td>\n",
       "      <td>77.570412</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>1</td>\n",
       "      <td>560065.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14098</th>\n",
       "      <td>ff8081815b15c304015b1df97fb2695f</td>\n",
       "      <td>BHK3</td>\n",
       "      <td>30-03-2017 12:36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>0</td>\n",
       "      <td>13.117724</td>\n",
       "      <td>77.577400</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0</td>\n",
       "      <td>560064.0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14099</th>\n",
       "      <td>ff8081815b1e0e51015b1e3ef2b51346</td>\n",
       "      <td>BHK2</td>\n",
       "      <td>30-03-2017 15:23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>0</td>\n",
       "      <td>13.103437</td>\n",
       "      <td>77.612229</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>560064.0</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>IH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14100 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            property_id  type   activation_date  bathroom  \\\n",
       "0      ff8080814a078fd2014a15c813ff0b03  BHK3  20-02-2017 09:24       3.0   \n",
       "1      ff8081814c2dea94014c50865ea35904  BHK2  11-03-2017 16:12       2.0   \n",
       "2      ff8081814cff7251014d04e2cc7018fd  BHK2  18-03-2017 14:26       2.0   \n",
       "3      ff8081814eb65997014ebbaa22f11869  BHK2  28-03-2017 11:09       2.0   \n",
       "4      ff8081814fa8748d014fabcabea10bb6  BHK3  14-02-2017 17:07       2.0   \n",
       "...                                 ...   ...               ...       ...   \n",
       "14095  ff8081815b15c304015b18b33e467d05  BHK3  29-03-2017 12:30       3.0   \n",
       "14096  ff8081815b15c304015b18f78f4e2503  BHK2  29-03-2017 13:18       2.0   \n",
       "14097  ff8081815b15c304015b1a4c67134ce4  BHK3  30-03-2017 14:10       1.0   \n",
       "14098  ff8081815b15c304015b1df97fb2695f  BHK3  30-03-2017 12:36       2.0   \n",
       "14099  ff8081815b1e0e51015b1e3ef2b51346  BHK2  30-03-2017 15:23       2.0   \n",
       "\n",
       "       floor  total_floor      furnishing gym   latitude  longitude  ...  \\\n",
       "0        2.0          6.0  SEMI_FURNISHED   1  12.872456  77.617578  ...   \n",
       "1        0.0          2.0  SEMI_FURNISHED   0  12.876009  77.617934  ...   \n",
       "2        2.0         19.0  SEMI_FURNISHED   1  12.875923  77.617946  ...   \n",
       "3        3.0          5.0  SEMI_FURNISHED   1  12.859438  77.614948  ...   \n",
       "4        1.0          3.0  SEMI_FURNISHED   0  12.875697  77.617187  ...   \n",
       "...      ...          ...             ...  ..        ...        ...  ...   \n",
       "14095    6.0          7.0  SEMI_FURNISHED   1  13.114465  77.578528  ...   \n",
       "14096    3.0          3.0  SEMI_FURNISHED   1  13.122433  77.582765  ...   \n",
       "14097    1.0         14.0  SEMI_FURNISHED   1  13.097357  77.570412  ...   \n",
       "14098    7.0         17.0  SEMI_FURNISHED   0  13.117724  77.577400  ...   \n",
       "14099    0.0          0.0  SEMI_FURNISHED   0  13.103437  77.612229  ...   \n",
       "\n",
       "      parking property_age property_size swimming_pool  pin_code     rent  \\\n",
       "0        BOTH          2.0        2000.0             0  560068.0  22000.0   \n",
       "1        BOTH          5.0        1250.0             0  560076.0  12500.0   \n",
       "2        BOTH          2.0        1279.0             1  560068.0  17500.0   \n",
       "3        BOTH          1.0        1200.0             0  560076.0  15000.0   \n",
       "4        BOTH          1.0        1550.0             0  560076.0  18000.0   \n",
       "...       ...          ...           ...           ...       ...      ...   \n",
       "14095    BOTH          6.0        1610.0             0  560064.0  20000.0   \n",
       "14096    BOTH          4.0        1155.0             1  560064.0  15000.0   \n",
       "14097    BOTH          5.0        1680.0             1  560065.0   8500.0   \n",
       "14098    BOTH          2.0        1326.0             0  560064.0  19000.0   \n",
       "14099    BOTH          0.0        1600.0             0  560064.0  11500.0   \n",
       "\n",
       "        deposit  building_type  location  \\\n",
       "0      150000.0             AP       NaN   \n",
       "1      125000.0             IF       NaN   \n",
       "2      175000.0             AP       NaN   \n",
       "3      100000.0             AP       NaN   \n",
       "4      100000.0             AP       NaN   \n",
       "...         ...            ...       ...   \n",
       "14095  200000.0             AP       NaN   \n",
       "14096  150000.0             AP       NaN   \n",
       "14097   60000.0             AP       NaN   \n",
       "14098  150000.0             AP       NaN   \n",
       "14099  100000.0             IH       NaN   \n",
       "\n",
       "       property_id/type/activation_date/bathroom/floor/total_floor/furnishing/gym/latitude/longitude/lease_type/lift/locality/parking/property_age/property_size/swimming_pool/pin_code/rent/deposit/building_type  \n",
       "0                                                    NaN                                                                                                                                                            \n",
       "1                                                    NaN                                                                                                                                                            \n",
       "2                                                    NaN                                                                                                                                                            \n",
       "3                                                    NaN                                                                                                                                                            \n",
       "4                                                    NaN                                                                                                                                                            \n",
       "...                                                  ...                                                                                                                                                            \n",
       "14095                                                NaN                                                                                                                                                            \n",
       "14096                                                NaN                                                                                                                                                            \n",
       "14097                                                NaN                                                                                                                                                            \n",
       "14098                                                NaN                                                                                                                                                            \n",
       "14099                                                NaN                                                                                                                                                            \n",
       "\n",
       "[14100 rows x 23 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmerged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "352e55d2-0f2b-402b-bfca-e3fee27312a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of properties in HSR Layout: 0%\n"
     ]
    }
   ],
   "source": [
    "hsr_layout_count = merged_df[merged_df['location'] == 'HSR Layout'].shape[0]\n",
    "total_properties = merged_df.shape[0]\n",
    "hsr_layout_percentage = (hsr_layout_count / total_properties) * 100\n",
    "print(f\"Percentage of properties in HSR Layout: {round(hsr_layout_percentage)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1f3610bc-cd40-48bf-900f-6f4126cfd0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of properties in HSR Layout: 0%\n"
     ]
    }
   ],
   "source": [
    "hsr_layout_count = merged_df[merged_df['location'] == 'HSR Layout'].shape[0]\n",
    "total_properties = merged_df.shape[0]\n",
    "hsr_layout_percentage = (hsr_layout_count / total_properties) * 100\n",
    "print(f\"Percentage of properties in HSR Layout: {round(hsr_layout_percentage)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6758a904-34b0-4a94-905c-14f1c076d9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of properties in HSR Layout: 0%\n"
     ]
    }
   ],
   "source": [
    "merged_df['location'] = merged_df['location'].str.strip().str.lower()\n",
    "hsr_layout_count = merged_df[merged_df['location'] == 'hsr layout'].shape[0]\n",
    "total_properties = merged_df.shape[0]\n",
    "hsr_layout_percentage = (hsr_layout_count / total_properties) * 100\n",
    "print(f\"Percentage of properties in HSR Layout: {round(hsr_layout_percentage)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f248dcc1-f8b2-4579-9fd9-ef1f78d3ebbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bommanahalli']\n",
      "location\n",
      "bommanahalli    224\n",
      "Name: count, dtype: int64\n",
      "Percentage of properties in HSR Layout: 0%\n"
     ]
    }
   ],
   "source": [
    "merged_df_clean = merged_df.dropna(subset=['location'])\n",
    "unique_locations_clean = merged_df_clean['location'].unique()\n",
    "print(unique_locations_clean)\n",
    "location_counts = merged_df_clean['location'].value_counts()\n",
    "print(location_counts)\n",
    "hsr_layout_count = location_counts.get('HSR Layout', 0)\n",
    "total_count = len(merged_df_clean)\n",
    "percentage_hsr_layout = (hsr_layout_count / total_count) * 100\n",
    "print(f\"Percentage of properties in HSR Layout: {round(percentage_hsr_layout)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a1363-5baf-4ae1-8f79-fee3a3cd0b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "06052a63-6bac-4e2e-b54d-7db0b609ba4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bommanahalli']\n"
     ]
    }
   ],
   "source": [
    "unique_locations = merged_df_clean['location'].unique()\n",
    "print(unique_locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "beff0f27-12e8-4a8c-8bca-3ca1a372ecf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>type</th>\n",
       "      <th>activation_date</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>floor</th>\n",
       "      <th>total_floor</th>\n",
       "      <th>furnishing</th>\n",
       "      <th>gym</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>parking</th>\n",
       "      <th>property_age</th>\n",
       "      <th>property_size</th>\n",
       "      <th>swimming_pool</th>\n",
       "      <th>pin_code</th>\n",
       "      <th>rent</th>\n",
       "      <th>deposit</th>\n",
       "      <th>building_type</th>\n",
       "      <th>location</th>\n",
       "      <th>property_id/type/activation_date/bathroom/floor/total_floor/furnishing/gym/latitude/longitude/lease_type/lift/locality/parking/property_age/property_size/swimming_pool/pin_code/rent/deposit/building_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ff8080814a078fd2014a15c813ff0b03</td>\n",
       "      <td>BHK3</td>\n",
       "      <td>20-02-2017 09:24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>1</td>\n",
       "      <td>12.872456</td>\n",
       "      <td>77.617578</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>560068.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ff8081814c2dea94014c50865ea35904</td>\n",
       "      <td>BHK2</td>\n",
       "      <td>11-03-2017 16:12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>0</td>\n",
       "      <td>12.876009</td>\n",
       "      <td>77.617934</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>560076.0</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>IF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ff8081814cff7251014d04e2cc7018fd</td>\n",
       "      <td>BHK2</td>\n",
       "      <td>18-03-2017 14:26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>1</td>\n",
       "      <td>12.875923</td>\n",
       "      <td>77.617946</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>1</td>\n",
       "      <td>560068.0</td>\n",
       "      <td>17500.0</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ff8081814eb65997014ebbaa22f11869</td>\n",
       "      <td>BHK2</td>\n",
       "      <td>28-03-2017 11:09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>1</td>\n",
       "      <td>12.859438</td>\n",
       "      <td>77.614948</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>560076.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ff8081814fa8748d014fabcabea10bb6</td>\n",
       "      <td>BHK3</td>\n",
       "      <td>14-02-2017 17:07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>0</td>\n",
       "      <td>12.875697</td>\n",
       "      <td>77.617187</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>0</td>\n",
       "      <td>560076.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14095</th>\n",
       "      <td>ff8081815b15c304015b18b33e467d05</td>\n",
       "      <td>BHK3</td>\n",
       "      <td>29-03-2017 12:30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>1</td>\n",
       "      <td>13.114465</td>\n",
       "      <td>77.578528</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>0</td>\n",
       "      <td>560064.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14096</th>\n",
       "      <td>ff8081815b15c304015b18f78f4e2503</td>\n",
       "      <td>BHK2</td>\n",
       "      <td>29-03-2017 13:18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>1</td>\n",
       "      <td>13.122433</td>\n",
       "      <td>77.582765</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>1</td>\n",
       "      <td>560064.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14097</th>\n",
       "      <td>ff8081815b15c304015b1a4c67134ce4</td>\n",
       "      <td>BHK3</td>\n",
       "      <td>30-03-2017 14:10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>1</td>\n",
       "      <td>13.097357</td>\n",
       "      <td>77.570412</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>1</td>\n",
       "      <td>560065.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14098</th>\n",
       "      <td>ff8081815b15c304015b1df97fb2695f</td>\n",
       "      <td>BHK3</td>\n",
       "      <td>30-03-2017 12:36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>0</td>\n",
       "      <td>13.117724</td>\n",
       "      <td>77.577400</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0</td>\n",
       "      <td>560064.0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14099</th>\n",
       "      <td>ff8081815b1e0e51015b1e3ef2b51346</td>\n",
       "      <td>BHK2</td>\n",
       "      <td>30-03-2017 15:23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SEMI_FURNISHED</td>\n",
       "      <td>0</td>\n",
       "      <td>13.103437</td>\n",
       "      <td>77.612229</td>\n",
       "      <td>...</td>\n",
       "      <td>BOTH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>560064.0</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>IH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14100 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            property_id  type   activation_date  bathroom  \\\n",
       "0      ff8080814a078fd2014a15c813ff0b03  BHK3  20-02-2017 09:24       3.0   \n",
       "1      ff8081814c2dea94014c50865ea35904  BHK2  11-03-2017 16:12       2.0   \n",
       "2      ff8081814cff7251014d04e2cc7018fd  BHK2  18-03-2017 14:26       2.0   \n",
       "3      ff8081814eb65997014ebbaa22f11869  BHK2  28-03-2017 11:09       2.0   \n",
       "4      ff8081814fa8748d014fabcabea10bb6  BHK3  14-02-2017 17:07       2.0   \n",
       "...                                 ...   ...               ...       ...   \n",
       "14095  ff8081815b15c304015b18b33e467d05  BHK3  29-03-2017 12:30       3.0   \n",
       "14096  ff8081815b15c304015b18f78f4e2503  BHK2  29-03-2017 13:18       2.0   \n",
       "14097  ff8081815b15c304015b1a4c67134ce4  BHK3  30-03-2017 14:10       1.0   \n",
       "14098  ff8081815b15c304015b1df97fb2695f  BHK3  30-03-2017 12:36       2.0   \n",
       "14099  ff8081815b1e0e51015b1e3ef2b51346  BHK2  30-03-2017 15:23       2.0   \n",
       "\n",
       "       floor  total_floor      furnishing gym   latitude  longitude  ...  \\\n",
       "0        2.0          6.0  SEMI_FURNISHED   1  12.872456  77.617578  ...   \n",
       "1        0.0          2.0  SEMI_FURNISHED   0  12.876009  77.617934  ...   \n",
       "2        2.0         19.0  SEMI_FURNISHED   1  12.875923  77.617946  ...   \n",
       "3        3.0          5.0  SEMI_FURNISHED   1  12.859438  77.614948  ...   \n",
       "4        1.0          3.0  SEMI_FURNISHED   0  12.875697  77.617187  ...   \n",
       "...      ...          ...             ...  ..        ...        ...  ...   \n",
       "14095    6.0          7.0  SEMI_FURNISHED   1  13.114465  77.578528  ...   \n",
       "14096    3.0          3.0  SEMI_FURNISHED   1  13.122433  77.582765  ...   \n",
       "14097    1.0         14.0  SEMI_FURNISHED   1  13.097357  77.570412  ...   \n",
       "14098    7.0         17.0  SEMI_FURNISHED   0  13.117724  77.577400  ...   \n",
       "14099    0.0          0.0  SEMI_FURNISHED   0  13.103437  77.612229  ...   \n",
       "\n",
       "      parking property_age property_size swimming_pool  pin_code     rent  \\\n",
       "0        BOTH          2.0        2000.0             0  560068.0  22000.0   \n",
       "1        BOTH          5.0        1250.0             0  560076.0  12500.0   \n",
       "2        BOTH          2.0        1279.0             1  560068.0  17500.0   \n",
       "3        BOTH          1.0        1200.0             0  560076.0  15000.0   \n",
       "4        BOTH          1.0        1550.0             0  560076.0  18000.0   \n",
       "...       ...          ...           ...           ...       ...      ...   \n",
       "14095    BOTH          6.0        1610.0             0  560064.0  20000.0   \n",
       "14096    BOTH          4.0        1155.0             1  560064.0  15000.0   \n",
       "14097    BOTH          5.0        1680.0             1  560065.0   8500.0   \n",
       "14098    BOTH          2.0        1326.0             0  560064.0  19000.0   \n",
       "14099    BOTH          0.0        1600.0             0  560064.0  11500.0   \n",
       "\n",
       "        deposit  building_type  location  \\\n",
       "0      150000.0             AP       NaN   \n",
       "1      125000.0             IF       NaN   \n",
       "2      175000.0             AP       NaN   \n",
       "3      100000.0             AP       NaN   \n",
       "4      100000.0             AP       NaN   \n",
       "...         ...            ...       ...   \n",
       "14095  200000.0             AP       NaN   \n",
       "14096  150000.0             AP       NaN   \n",
       "14097   60000.0             AP       NaN   \n",
       "14098  150000.0             AP       NaN   \n",
       "14099  100000.0             IH       NaN   \n",
       "\n",
       "       property_id/type/activation_date/bathroom/floor/total_floor/furnishing/gym/latitude/longitude/lease_type/lift/locality/parking/property_age/property_size/swimming_pool/pin_code/rent/deposit/building_type  \n",
       "0                                                    NaN                                                                                                                                                            \n",
       "1                                                    NaN                                                                                                                                                            \n",
       "2                                                    NaN                                                                                                                                                            \n",
       "3                                                    NaN                                                                                                                                                            \n",
       "4                                                    NaN                                                                                                                                                            \n",
       "...                                                  ...                                                                                                                                                            \n",
       "14095                                                NaN                                                                                                                                                            \n",
       "14096                                                NaN                                                                                                                                                            \n",
       "14097                                                NaN                                                                                                                                                            \n",
       "14098                                                NaN                                                                                                                                                            \n",
       "14099                                                NaN                                                                                                                                                            \n",
       "\n",
       "[14100 rows x 23 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c735f92e-2aa2-4dff-9bb4-9a2aeb4f3636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent property age category: New\n"
     ]
    }
   ],
   "source": [
    "def categorize_age(age):\n",
    "    if age <= 1:\n",
    "        return 'New'\n",
    "    elif 1 < age <= 5:\n",
    "        return 'Less than 5 years'\n",
    "    elif 5 < age <= 10:\n",
    "        return '5 to 10 years'\n",
    "    elif 10 < age <= 20:\n",
    "        return '10 to 20 years'\n",
    "    else:\n",
    "        return 'More than 20 years'\n",
    "\n",
    "merged_df['property_age_category'] = merged_df['property_age'].apply(categorize_age)\n",
    "most_frequent_category = merged_df['property_age_category'].mode()[0]\n",
    "print(f\"Most frequent property age category: {most_frequent_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c01e8076-4a2e-48c6-a974-7bcc65951a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['property_id', 'type', 'activation_date', 'bathroom', 'floor',\n",
      "       'total_floor', 'furnishing', 'gym', 'latitude', 'longitude',\n",
      "       'lease_type', 'lift', 'locality', 'parking', 'property_age',\n",
      "       'property_size', 'swimming_pool', 'pin_code', 'rent', 'deposit',\n",
      "       'building_type', 'location',\n",
      "       'property_id/type/activation_date/bathroom/floor/total_floor/furnishing/gym/latitude/longitude/lease_type/lift/locality/parking/property_age/property_size/swimming_pool/pin_code/rent/deposit/building_type',\n",
      "       'property_age_category'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "68c3b944-b7e0-467e-95eb-e36db1759d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apartment type with highest average rent: BHK4PLUS\n"
     ]
    }
   ],
   "source": [
    "avg_rent_by_type = merged_df.groupby('type')['rent'].mean()\n",
    "highest_avg_rent_type = avg_rent_by_type.idxmax()\n",
    "print(f\"Apartment type with highest average rent: {highest_avg_rent_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7dedfef6-fd05-4f3c-8e03-a4199ca9f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'True'/'False' string values to 1/0\n",
    "merged_df['gym'] = merged_df['gym'].replace({'True': 1, 'False': 0})\n",
    "merged_df['lift'] = merged_df['lift'].replace({'True': 1, 'False': 0})\n",
    "merged_df['swimming_pool'] = merged_df['swimming_pool'].replace({'True': 1, 'False': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "57225094-dc61-419b-bb2c-d3816a6f1539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gym  lift  swimming_pool\n",
      "0  1.0   1.0            0.0\n",
      "1  0.0   0.0            0.0\n",
      "2  1.0   1.0            1.0\n",
      "3  1.0   1.0            0.0\n",
      "4  0.0   1.0            0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suras\\AppData\\Local\\Temp\\ipykernel_5292\\3986579856.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['gym'] = merged_df['gym'].replace({'True': 1, 'False': 0, 'Flase': 0})\n",
      "C:\\Users\\suras\\AppData\\Local\\Temp\\ipykernel_5292\\3986579856.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['lift'] = merged_df['lift'].replace({'True': 1, 'False': 0, 'Flase': 0})\n",
      "C:\\Users\\suras\\AppData\\Local\\Temp\\ipykernel_5292\\3986579856.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['swimming_pool'] = merged_df['swimming_pool'].replace({'True': 1, 'False': 0, 'Flase': 0})\n"
     ]
    }
   ],
   "source": [
    "merged_df['gym'] = merged_df['gym'].replace({'True': 1, 'False': 0, 'Flase': 0})\n",
    "merged_df['lift'] = merged_df['lift'].replace({'True': 1, 'False': 0, 'Flase': 0})\n",
    "merged_df['swimming_pool'] = merged_df['swimming_pool'].replace({'True': 1, 'False': 0, 'Flase': 0})\n",
    "print(merged_df[['gym', 'lift', 'swimming_pool']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7ea08abd-a146-41a9-abd7-6f418a22b948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between amenities and rent:\n",
      "gym              0.393666\n",
      "lift             0.416619\n",
      "swimming_pool    0.396103\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a correlation matrix for the amenities and rent\n",
    "amenities_columns = ['gym', 'lift', 'swimming_pool']\n",
    "correlations = merged_df[amenities_columns].corrwith(merged_df['rent'])\n",
    "\n",
    "# Print the correlation values\n",
    "print(\"Correlation between amenities and rent:\")\n",
    "print(correlations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a4cdf55a-5042-4277-b635-d091dbc6e3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest interaction count: 3.0\n",
      "Property details with the highest interaction count:\n",
      "         locality                       property_id  interaction_metric\n",
      "1248    Bellandur  ff808081482565740148261980670079                 3.0\n",
      "1249    Bellandur  ff80808149b8764a0149bda1f264039d                 3.0\n",
      "1260    Bellandur  ff8081815185752901518661318b1371                 3.0\n",
      "1263    Bellandur  ff80818152ab65b30152c00804863884                 3.0\n",
      "1266    Bellandur  ff808181534744b101534aad00d418a9                 3.0\n",
      "...           ...                               ...                 ...\n",
      "13546  Whitefield  ff8081815b0aa1c2015b0e78277070cf                 3.0\n",
      "13548  Whitefield  ff8081815b0f86d4015b0fb2b3ff1581                 3.0\n",
      "13549  Whitefield  ff8081815b0f86d4015b0fb54da016d4                 3.0\n",
      "13553  Whitefield  ff8081815b106986015b13afad3d7256                 3.0\n",
      "13559  Whitefield  ff8081815b15c304015b18d7f88f1270                 3.0\n",
      "\n",
      "[510 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suras\\AppData\\Local\\Temp\\ipykernel_5292\\1851027579.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_localities_df['interaction_metric'] = (\n"
     ]
    }
   ],
   "source": [
    "average_rent_by_locality = merged_df.groupby('locality')['rent'].mean()\n",
    "top_5_localities = average_rent_by_locality.nlargest(5).index\n",
    "top_localities_df = merged_df[merged_df['locality'].isin(top_5_localities)]\n",
    "top_localities_df['interaction_metric'] = (\n",
    "    top_localities_df['gym'].fillna(0) +\n",
    "    top_localities_df['lift'].fillna(0) +\n",
    "    top_localities_df['swimming_pool'].fillna(0)\n",
    ")\n",
    "highest_interaction_count = top_localities_df['interaction_metric'].max()\n",
    "property_with_highest_interactions = top_localities_df[top_localities_df['interaction_metric'] == highest_interaction_count]\n",
    "print(f\"Highest interaction count: {highest_interaction_count}\")\n",
    "print(\"Property details with the highest interaction count:\")\n",
    "print(property_with_highest_interactions[['locality', 'property_id', 'interaction_metric']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a141a53-5ea0-434c-a9be-3bebda61c32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1869df6c-7ff4-448b-aa66-39ed5ee2b032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of properties available for lease under the 'Anyone' category: 0%\n"
     ]
    }
   ],
   "source": [
    "anyone_lease_properties = merged_df[merged_df['lease_type'] == 'Anyone']\n",
    "total_properties = len(merged_df)  \n",
    "anyone_lease_count = len(anyone_lease_properties)\n",
    "percentage_anyone_lease = (anyone_lease_count / total_properties) * 100\n",
    "print(f\"Percentage of properties available for lease under the 'Anyone' category: {percentage_anyone_lease:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d85b09f6-6ae7-493c-82f1-63f12c5c8aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The date with the most properties activated: 2017-03-02 19:23:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suras\\AppData\\Local\\Temp\\ipykernel_5292\\4033507672.py:2: UserWarning: Parsing dates in %d-%m-%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  merged_df['activation_date'] = pd.to_datetime(merged_df['activation_date'])\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Convert 'activation_date' to datetime format if it's not already\n",
    "merged_df['activation_date'] = pd.to_datetime(merged_df['activation_date'])\n",
    "\n",
    "# Step 2: Count the number of properties activated on each date\n",
    "activation_counts = merged_df['activation_date'].value_counts()\n",
    "\n",
    "# Step 3: Get the date with the most properties activated\n",
    "most_activated_date = activation_counts.idxmax()\n",
    "\n",
    "# Step 4: Print the result\n",
    "print(f\"The date with the most properties activated: {most_activated_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "97b0e728-b341-4d81-bb21-28b3bc3c3bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent time category is: Afternoon\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "merged_df['activation_date'] = pd.to_datetime(merged_df['activation_date'])\n",
    "def categorize_time(hour):\n",
    "    if 0 <= hour < 6:\n",
    "        return 'Midnight'\n",
    "    elif 6 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 18:\n",
    "        return 'Afternoon'\n",
    "    else:\n",
    "        return 'Evening'\n",
    "\n",
    "# Apply the function to create the new column\n",
    "merged_df['time_category'] = merged_df['activation_date'].dt.hour.apply(categorize_time)\n",
    "\n",
    "# Identify the most frequent time category\n",
    "most_frequent_time_category = merged_df['time_category'].mode()[0]\n",
    "\n",
    "# Display the result\n",
    "print(f\"The most frequent time category is: {most_frequent_time_category}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "97304d31-461b-4e66-b311-fe26cd0b943d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique locations: 1\n"
     ]
    }
   ],
   "source": [
    "unique_locations_count = merged_df['location'].nunique\n",
    "print(f\"Number of unique locations: {unique_locations_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe9627-577a-4785-846e-13c9e817ba7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
